{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.1) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title:  \n",
      "\"Journey to the Stars: 3030\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['theme', 'year'], template=template)\n",
    "\n",
    "input_data = {'theme': 'interstellar travel', 'year': \"3030\"}\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: purple\n",
      "Emotion:   creativity\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {'color': 'red', 'emotion': 'passion'},\n",
    "    {'color': 'blue', 'emotion': 'serenity'},\n",
    "    {'color': 'green', 'emotion': 'tranquility'}\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=['color', 'emotion'],\n",
    "                                template=example_formatter_template)\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(examples=examples,\n",
    "                                        example_prompt=example_prompt,\n",
    "                                        prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
    "                                        suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "                                        input_variables=['input'],\n",
    "                                        example_separator='\\n')\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input='purple')\n",
    "\n",
    "prompt = PromptTemplate(template=formatted_prompt, input_variables=[])\n",
    "\n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt)\n",
    "\n",
    "response = chain.run({})\n",
    "\n",
    "print('Color: purple')\n",
    "print('Emotion: ', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: \n",
      "Albert Einstein's theory of general relativity is a theory of gravitation that states that the gravitational force between two objects is a result of the curvature of spacetime caused by the presence of mass and energy. It explains the phenomenon of gravity as a result of the warping of space and time by matter and energy.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_fact = PromptTemplate(input_variables=['scientist'], template=template_fact)\n",
    "\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "scientist = response_question.strip()\n",
    "\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "input_data = {'scientist': scientist}\n",
    "\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print('Scientist:', scientist)\n",
    "print('Fact:', response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A well-structured prompt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response:  Practice active listening, be mindful of your body language, and be open to feedback.\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {'query': \"What's the secret to happiness?\",\n",
    "     'answer': \"Finding balance in life and learning to enjoy the small\"},\n",
    "    {'query': \"How can I become more productive?\",\n",
    "     'answer': \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"}\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=['query', 'answer'],\n",
    "                                template=example_template)\n",
    "\n",
    "prefix = \"\"\"\n",
    "The following are excerpts from conversations with an AI life coach. The assistant provides insightful\n",
    "and practical advice to the users' questions. Here are some examples:\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=['query'],\n",
    "    example_separator='\\n\\n'\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "response = chain.run({'query': user_query})\n",
    "\n",
    "print('User Query:', user_query)\n",
    "print('AI Response:', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
