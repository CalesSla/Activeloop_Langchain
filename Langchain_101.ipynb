{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.0) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "1. Start with a 5-minute warm up at an easy pace. \n",
      "2. Sprint for 30 seconds, rest for 1 minute. \n",
      "3. Run uphill for 2 minutes. \n",
      "4. Sprint for 30 seconds, rest for 1 minute. \n",
      "5. Sprint for 2 minutes, rest for 1 minute. \n",
      "6. Repeat the sequence 4-5 times.\n",
      "7. Jog or walk for 10 minutes to cool down. \n",
      "8. Stretch for 5 minutes. \n",
      "9. Repeat this workout 2-3 times a week.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model='text-davinci-003', temperature=0.9)\n",
    "\n",
    "text = 'Suggest a personalised workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.'\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main components of an LLMChain constructor in langchain:\n",
    "* PromptTemplate - to format the input variables into a prompt\n",
    "* A model - either LLM or ChatModel\n",
    "* Output parser (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EcoBubbles.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model='text-davinci-003', temperature=0.9)\n",
    "\n",
    "template=\"What is a good name for a company that makes {product}?\"\n",
    "prompt = PromptTemplate(input_variables=['product'], template=template)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run('eco-friendly water bottles'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Tell me  about yourself\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! My name is AI and I'm a virtual assistant. I'm here to help you with any questions you may have. I'm programmed to understand natural language and provide answers to your questions. I'm also able to provide helpful information about a variety of topics. What would you like to know?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(model='text-davinci-003', temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True, memory=ConversationBufferMemory())\n",
    "\n",
    "conversation.predict(input=\"Tell me  about yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me  about yourself\n",
      "AI:  Hi there! My name is AI and I'm a virtual assistant. I'm here to help you with any questions you may have. I'm programmed to understand natural language and provide answers to your questions. I'm also able to provide helpful information about a variety of topics. What would you like to know?\n",
      "Human: What can you do?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm able to provide helpful information about a variety of topics. I can answer questions, provide recommendations, and even help you with tasks like scheduling appointments or making reservations. I'm also able to provide personalized recommendations based on your preferences.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What can you do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me  about yourself\n",
      "AI:  Hi there! My name is AI and I'm a virtual assistant. I'm here to help you with any questions you may have. I'm programmed to understand natural language and provide answers to your questions. I'm also able to provide helpful information about a variety of topics. What would you like to know?\n",
      "Human: What can you do?\n",
      "AI:  I'm able to provide helpful information about a variety of topics. I can answer questions, provide recommendations, and even help you with tasks like scheduling appointments or making reservations. I'm also able to provide personalized recommendations based on your preferences.\n",
      "Human: How can you help me with data analysis?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm not able to help you with data analysis directly, but I can provide you with resources and information that can help you with data analysis. I can also help you find experts in the field who can provide you with more detailed advice.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"How can you help me with data analysis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Tell me  about yourself', additional_kwargs={}, example=False), AIMessage(content=\" Hi there! My name is AI and I'm a virtual assistant. I'm here to help you with any questions you may have. I'm programmed to understand natural language and provide answers to your questions. I'm also able to provide helpful information about a variety of topics. What would you like to know?\", additional_kwargs={}, example=False), HumanMessage(content='What can you do?', additional_kwargs={}, example=False), AIMessage(content=\" I'm able to provide helpful information about a variety of topics. I can answer questions, provide recommendations, and even help you with tasks like scheduling appointments or making reservations. I'm also able to provide personalized recommendations based on your preferences.\", additional_kwargs={}, example=False), HumanMessage(content='How can you help me with data analysis?', additional_kwargs={}, example=False), AIMessage(content=\" I'm not able to help you with data analysis directly, but I can provide you with resources and information that can help you with data analysis. I can also help you find experts in the field who can provide you with more detailed advice.\", additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history') callbacks=None callback_manager=None verbose=True tags=None prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:', template_format='f-string', validate_template=True) llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all') output_key='response' output_parser=NoOpOutputParser() return_final_only=True llm_kwargs={} input_key='input'\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DeepLake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://veaceslavcalestru/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://veaceslavcalestru/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (8, 1536)  float32   None   \n",
      "    id        text      (8, 1)      str     None   \n",
      " metadata     json      (8, 1)      str     None   \n",
      "   text       text      (8, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c55d302b-6916-11ee-b60b-cc4740c98b6b',\n",
       " 'c55d302c-6916-11ee-98a7-cc4740c98b6b']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = OpenAI(model='text-davinci-003', temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "# create documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "my_activeloop_org_id = \"veaceslavcalestru\"\n",
    "my_activeloop_dataset_name = 'langchain_course_from_zero_to_hero'\n",
    "dataset_path = f'hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}'\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Napoleone was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Napoleone born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Napoleon Bonaparte was born on 15 August 1769.\n"
     ]
    }
   ],
   "source": [
    "retrieval_qa = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=db.as_retriever())\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [Tool(name='Retrieval QA System',\n",
    "              func=retrieval_qa.run,\n",
    "              description=\"Useful for answering questions.\")]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading an existing vector store and adding more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://veaceslavcalestru/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://veaceslavcalestru/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (10, 1536)  float32   None   \n",
      "    id        text      (10, 1)      str     None   \n",
      " metadata     json      (10, 1)      str     None   \n",
      "   text       text      (10, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dc3fb13f-6916-11ee-b8f9-cc4740c98b6b',\n",
       " 'dc3fb140-6916-11ee-9aea-cc4740c98b6b']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "texts = [\n",
    "    \"Lady Gaga was born in 28 March 1986\",\n",
    "    \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate previous agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Michael Jordan was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Michael Jordan born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Michael Jordan was born on 17 February 1963.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model='text-davinci-003', temperature=0)\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=db.as_retriever())\n",
    "\n",
    "tools = [Tool(name='Retrieval QA System',\n",
    "              func=retrieval_qa.run,\n",
    "              description=\"Useful for answering questions.\")]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "response = agent.run(\"When was Michael Jordan born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about the Mars rover\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The multi-mission Mars ... New evidence suggests salty, shallow ponds once dotted a Martian crater — a sign of the planet's drying climate. More. Get the Mars Newsletter ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... Curiosity Rover · Nasa's Curiosity Mars rover can provide a lot of information about the Red Planet, but · An image taken by the Nasa Spirit rover, which shows ... Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ... Mars ; Rover captures one-mile-high whirlwind on Mars · Scientists are developing methods of identifying life on other planets (David Davies/PA) · Science ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for Breaking News Alerts. Apr 28, 2023 ... Friday's news comes days after mission leaders acknowledged that the Zhurong rover has yet to wake up since going into hibernation for the ... Aug 10, 2023 ... Sky News: Breaking, UK & World. Sky UK Limited. FREE - In Google Play ... This panorama captured by NASA's Curiosity Mars rover shows a location ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest news about the Mars rover is that the mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. China's Mars rover has likely suffered excessive damage due to hibernation, and Curiosity rover has found a water-carved 'book' rock on Mars. Additionally, a one-mile-high whirlwind was captured by the Mars rover, and scientists are developing methods of identifying life on other planets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover is that the mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. China's Mars rover has likely suffered excessive damage due to hibernation, and Curiosity rover has found a water-carved 'book' rock on Mars. Additionally, a one-mile-high whirlwind was captured by the Mars rover, and scientists are developing methods of identifying life on other planets.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "import os\n",
    "\n",
    "llm = OpenAI(model = 'text-davinci-003', temperature=0)\n",
    "\n",
    "#define google search wrapper\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [Tool(name='google-search',\n",
    "              func=search.run,\n",
    "              description=\"useful for when you need to search google to answer questions about current events\")]\n",
    "\n",
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True,\n",
    "                         max_iterations=6)\n",
    "\n",
    "response = agent(\"What's the latest news about the Mars rover?\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for recent news about the Mars rover and then summarize the results.\n",
      "Action: Search\n",
      "Action Input: Latest news about the Mars rover\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mData sent by the spacecraft before it retired last December has provided new details about how fast the planet fast rotates and how much it wobbles. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The multi-mission Mars ... NASA's Curiosity Mars rover captured these clouds just after sunset on March 19, 2021, ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Jun 28, 2023 ... Informally dubbed by Hecht and his team as \"the last hurrah,\" MOXIE delivered the goods on its 15th run on Mars since first gulping up Martian ... Mars ; Rover captures one-mile-high whirlwind on Mars · Scientists are developing methods of identifying life on other planets (David Davies/PA) · Science ... Feb 8, 2023 ... NASA's Curiosity Mars rover has discovered lots of evidence of ancient lakes on the Red Planet – and this recent panorama shows intriguing ... Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for Breaking News Alerts.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should summarize the results.\n",
      "Action: Summarizer\n",
      "Action Input: Data sent by the spacecraft before it retired last December has provided new details about how fast the planet fast rotates and how much it wobbles. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The multi-mission Mars ... NASA's Curiosity Mars rover captured these clouds just after sunset on March 19, 2021, ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Jun 28, 2023 ... Informally dubbed by Hecht and his team as \"the last hurrah,\" MOXIE delivered the goods on its 15th run on Mars since first gulping up Martian ... Mars ; Rover captures one-mile-high whirlwind on Mars · Scientists are developing methods of identifying life on other planets (David Davies/PA) · Science ... Feb 8, 20\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m26\n",
      "\n",
      "Data sent by the spacecraft before it retired in December 2020 has revealed new information about the speed of Mars' rotation and its wobble. NASA's Curiosity Mars rover captured clouds in March 2021, and a book-shaped rock likely carved by ancient water. The Mars 2020 Perseverance rover will look for signs of past microbial life and cache rock and soil samples. In June 2023, MOXIE delivered its 15th run on Mars. In February 2026, scientists are developing methods of identifying life on other planets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The latest news about the Mars rover is that data sent by the spacecraft before it retired in December 2020 has revealed new information about the speed of Mars' rotation and its wobble, NASA's Curiosity Mars rover captured clouds in March 2021, and a book-shaped rock likely carved by ancient water. The Mars 2020 Perseverance rover will look for signs of past microbial life and cache rock and soil samples. In June 2023, MOXIE delivered its 15th run on Mars. In February 2026, scientists are developing methods of identifying life on other planets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover is that data sent by the spacecraft before it retired in December 2020 has revealed new information about the speed of Mars' rotation and its wobble, NASA's Curiosity Mars rover captured clouds in March 2021, and a book-shaped rock likely carved by ancient water. The Mars 2020 Perseverance rover will look for signs of past microbial life and cache rock and soil samples. In June 2023, MOXIE delivered its 15th run on Mars. In February 2026, scientists are developing methods of identifying life on other planets.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "llm = OpenAI(model='text-davinci-003', temperature=0)\n",
    "\n",
    "template = 'Write a summary of the following text: {query}'\n",
    "prompt = PromptTemplate(input_variables=['query'],\n",
    "                        template=template)\n",
    "\n",
    "summarize_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [Tool(name='Search',\n",
    "              func=search.run,\n",
    "              description='useful for finding information about recent events'),\n",
    "         Tool(name='Summarizer',\n",
    "              func=summarize_chain.run,\n",
    "              description='useful for summarizing texts')]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "response = agent(\"What's the latest news about the Mars rover? Then please summarize the results.\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
